{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "'''\n@author: Ishan Mohanty\nEE660: Machine Learning From Signals\n'''\n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport gc, sys\ngc.enable()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Thanks and credited to https://www.kaggle.com/gemartin who created this wonderful mem reducer\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5568b38111cf92546d22d1d7860550e460fb7030"
      },
      "cell_type": "code",
      "source": "def select_dataset(is_train=True, choose_train_sample=True):\n      \n    if is_train: \n        print(\"selecting and sampling the training dataset\")\n        if choose_train_sample == True:\n            df = pd.read_csv('../input/train_V2.csv', nrows=10000)\n        else:\n            df = pd.read_csv('../input/train_V2.csv')           \n\n        df = df[df['maxPlace'] > 1]\n    else:\n        print(\"selecting test dataset\")\n        df = pd.read_csv('../input/test_V2.csv')\n    \n    print(\"done ...\")\n    \n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ab23fb7c0d9537c50f910e44e046707e23a5366"
      },
      "cell_type": "code",
      "source": "def feature_expansion(df):\n    \n    print(\"Starting feature expansion\")\n    \n    df['headshotrate'] = df['kills']/df['headshotKills']\n    df['killStreakrate'] = df['killStreaks']/df['kills']\n    df['healthitems'] = df['heals'] + df['boosts']\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n    df[\"skill\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n    df['items'] = df['heals'] + df['boosts']\n    df['teamwork'] = df['assists'] + df['revives']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN    \n    print(\"Removing all NaN's from the dataset\")\n    df.fillna(0, inplace=True)\n    \n    print(\"Feature expansion completed\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3be878879edaae4b163ac3880db775ce57eb29de"
      },
      "cell_type": "code",
      "source": "def processing_features(df,is_train=True):\n    \n    if is_train:\n        test_idx = None\n    else:\n        test_idx = df.Id\n        \n    print(\"deleting specific columns\")\n    target = 'winPlacePerc'\n    \n    features = list(df.columns)\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchType\")\n     \n    y = None\n       \n    if is_train: \n        print(\"retrieve target\")\n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        features.remove(target)\n\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    else: df_out = df[['matchId','groupId']]\n\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n\n    X = df_out\n    \n    feature_names = list(df_out.columns)\n\n    del df, df_out, agg, agg_rank\n    gc.collect()\n\n    return X, y, feature_names, test_idx",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27b390572092dafa9c5fa9170c4bd56c89451a7b"
      },
      "cell_type": "code",
      "source": "df_train = select_dataset(True,False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc08470cb5e8281ab0328b3b0f3f6b7095dcadda"
      },
      "cell_type": "code",
      "source": "feature_expansion(df_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f68071adf26ab1600e427300a08720e39229702"
      },
      "cell_type": "code",
      "source": "x_train, y_train, train_columns, _ = processing_features(df_train,True)\nx_train = reduce_mem_usage(x_train)\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9411c3fc9b424cbe6e54b79d766b427c6ce9094"
      },
      "cell_type": "code",
      "source": "df_test = select_dataset(False,True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98f73689c733aaf676ddcb338622797d58f4bbcb"
      },
      "cell_type": "code",
      "source": "feature_expansion(df_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3d0794d3595f693d4a8159601cac3ac6c492cce9"
      },
      "cell_type": "code",
      "source": "x_test, _, _ , test_idx = processing_features(df_test,False)\nx_test = reduce_mem_usage(x_test)\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b986104b52ba35ae8f33f7db2b58cc519d1c960"
      },
      "cell_type": "code",
      "source": "idx_train = round(int(x_train.shape[0]*0.8))\nsample_train_x = x_train[:idx_train] \nsample_valid_x = x_train[idx_train:]\nsample_train_y = y_train[:idx_train] \nsample_valid_y = y_train[idx_train:] \ngc.collect();\n\ndef train_algo(training_X, training_y, valid_X, valid_y, x_test):\n    params = {\"objective\" : \"regression\", \"metric\" : \"mae\", 'n_estimators': 20000, 'early_stopping_rounds': 200,\n              \"num_leaves\" : 31, \"learning_rate\" : 0.05, \"bagging_fraction\" : 0.7,\n               \"bagging_seed\" : 0, \"num_threads\" : 4,\"colsample_bytree\" : 0.7\n             }\n    \n    lgbm_train = lgb.Dataset(training_X, label=training_y)\n    lgbm_val = lgb.Dataset(valid_X, label=valid_y)\n    model = lgb.train(params, lgbm_train, valid_sets=[lgbm_train, lgbm_val], early_stopping_rounds=200, verbose_eval=1000)\n    \n    pred_test = model.predict(x_test, num_iteration=model.best_iteration)\n    return pred_test, model\n\nprediction, model = train_algo(sample_train_x, sample_train_y , sample_valid_x, sample_valid_y, x_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6fa1274d4ac7d369aeba286aa696d73140734eb7"
      },
      "cell_type": "code",
      "source": "df_sub = pd.read_csv(\"../input/sample_submission_V2.csv\")\ndf_test = pd.read_csv(\"../input/test_V2.csv\")\ndf_sub['winPlacePerc'] = prediction\n# Restore some columns\ndf_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"maxPlace\", \"numGroups\"]], on=\"Id\", how=\"left\")\n\n# Sort, rank, and assign adjusted ratio\ndf_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\ndf_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\ndf_sub_group = df_sub_group.merge(\n    df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n    on=\"matchId\", how=\"left\")\ndf_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n\ndf_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\ndf_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]\n\n# Deal with edge cases\ndf_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\ndf_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n\n# Align with maxPlace\n# Credit: https://www.kaggle.com/anycode/simple-nn-baseline-4\nsubset = df_sub.loc[df_sub.maxPlace > 1]\ngap = 1.0 / (subset.maxPlace.values - 1)\nnew_perc = np.around(subset.winPlacePerc.values / gap) * gap\ndf_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n\n# Edge case\ndf_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\nassert df_sub[\"winPlacePerc\"].isnull().sum() == 0\n\ndf_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"finalv2_submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}